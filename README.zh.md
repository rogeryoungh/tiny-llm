# Tiny LLM

ä¸€ä¸ªä½¿ç”¨ C++ å®ç°çš„å¤§æ¨¡å‹æ¨ç†å¼•æ“ï¼Œæ”¯æŒä¸­æ–‡ï¼ˆUTF-8ï¼‰è¾“å…¥ã€‚

> [!WARNING]
> ğŸš§ é¡¹ç›®ä»åœ¨æŒç»­å¼€å‘ä¸­ã€‚

## ç‰¹æ€§

- çº¯ C++ å®ç°ï¼Œæ”¯æŒ CPUã€CUDA æ¨ç†
- Tokenizer é‡‡ç”¨ popcount trie ä¼˜åŒ–ï¼Œå†…å­˜å ç”¨ä½ï¼Œå€Ÿé‰´ [cloudflare/trie-hard](https://github.com/cloudflare/trie-hard)
- å…¼å®¹ Huggingface safetensors æƒé‡æ ¼å¼
- æ”¯æŒ UTF-8 ç¼–ç ï¼Œé€‚åˆä¸­æ–‡åœºæ™¯
- å·²åœ¨ [Qwen2.5-3B](https://huggingface.co/Qwen/Qwen2.5-3B)ã€[Qwen3-4B](https://huggingface.co/Qwen/Qwen2.5-3B/) å’Œ [Mistral-7B-Instruct-v0.2](https://huggingface.co/mistralai/Mistral-7B-Instruct-v0.2) ç­‰æ¨¡å‹ä¸Šè¿›è¡Œæµ‹è¯•
- æ”¯æŒä»¥ bf16ã€fp16 æˆ– fp32 æ ¼å¼åŠ è½½æƒé‡

## ä½¿ç”¨

é¦–å…ˆä¸‹è½½æ¨¡å‹å’Œæƒé‡ï¼Œç„¶åç¼–è¯‘ï¼Œå³å¯åœ¨ CPU ä¸Šè¿è¡Œã€‚

```bash
git clone git@hf.co:Qwen/Qwen2.5-3B
xmake
# ç”Ÿæˆçš„å¯æ‰§è¡Œæ–‡ä»¶ä½äº ./build/linux/x86_64/release/tiny-llm
xmake run tiny-llm -m ./Qwen2.5-3B --prompt "ä»‹ç»ä¸€ä¸‹æ­å·çš„ç¾é£Ÿã€‚" --device=cpu
```

**åœ¨ CUDA ä¸Šè¿è¡Œéœ€è¦å…ˆè½¬åŒ–ä¸º fp16ã€‚**

æˆ‘æä¾›äº†ä¸€ä¸ª Python è„šæœ¬ç”¨äºæŠŠæƒé‡è½¬åŒ–ä¸º bf16ã€fp16 æˆ– fp32ã€‚

```bash
uv init # å®‰è£…ä¾èµ–
uv run scripts/convert.py --src ./Qwen2.5-3B/ --dst ./Qwen2.5-3B-fp16 --dtype fp16
xmake run tiny-llm -m ./Qwen2.5-3B-fp16 --prompt "ä»‹ç»ä¸€ä¸‹æ­å·çš„ç¾é£Ÿã€‚" --device=cuda
```

## æ€§èƒ½æµ‹è¯•

ä¸ºä¾¿äºæ€§èƒ½æµ‹è¯•ï¼Œæˆ‘ä½¿ç”¨ç©ºæ ¼å°† prompt å¡«å……è‡³å›ºå®šé•¿åº¦ã€‚å…·ä½“çš„æµ‹è¯•è„šæœ¬è§ `scripts/benchmark.sh`ã€‚

æµ‹è¯•ç¯å¢ƒå¦‚ä¸‹ï¼š

- CPUï¼šAMD 9950xï¼ˆ16 æ ¸ 32 çº¿ç¨‹ï¼‰
- å†…å­˜ï¼šDDR5 48GB x2ï¼Œ6400MHz CL32
- æ˜¾å¡ï¼šRTX 5070 Tiï¼ŒGDDR7 16GBï¼Œå¸¦å®½ 896 GB/sï¼Œ256 bit æ€»çº¿

æµ‹è¯•å‚æ•°ï¼š

- kv-size=4096
- prompt=32
- max-output=512

### CUDA

æ€§èƒ½å•ä½æ˜¯ token/sã€‚

| æ¨¡å‹åç§°                 | å‚æ•°é‡  | ç²¾åº¦   | é‡‡æ ·     | Prefill | Gen å¹³å‡ | é¦–32    | æœ«32    |
| ------------------------ | ----- | ---- | -------- | ------- | ------ | ------ | ------ |
| Mistral-7B-Instruct-v0.3 | 7.25B | fp16 | Argmax   | 54.65   | 51.62  | 53.25  | 51.36  |
| Qwen2.5-3B               | 3.09B | fp16 | Argmax   | 116.18  | 101.26 | 105.68 | 100.24 |
| Qwen2.5-7B-Instruct      | 7.62B | fp16 | Sampling | 57.27   | 52.04  | 53.17  | 52.39  |
| Qwen3-4B                 | 4.02B | fp16 | Sampling | 92.16   | 78.88  | 83.24  | 76.51  |
| Qwen3-0.6B               | 0.75B  | fp16 | Sampling | 376.89  | 283.99 | 314.57 | 268.62 |

### CPU

æ€§èƒ½å•ä½æ˜¯ token/sã€‚


| æ¨¡å‹åç§°                 | å‚æ•°é‡  | ç²¾åº¦   | é‡‡æ ·     | Prefill | Gen å¹³å‡ | é¦–32   | æœ«32  |
| ------------------------ | ----- | ---- | -------- | ------- | ------ | ----- | ---- |
| Mistral-7B-Instruct-v0.3 | 7.25B | fp16 | Argmax   | 3.84    | 2.82   | 3.68  | 2.00 |
| Mistral-7B-Instruct-v0.3 | 7.25B | bf16 | Argmax   | 3.92    | 2.52   | 3.76  | 1.75 |
| Qwen2.5-3B               | 3.09B | fp16 | Argmax   | 7.47    | 6.18   | 6.90  | 5.80 |
| Qwen2.5-3B               | 3.09B | bf16 | Argmax   | 7.70    | 6.34   | 7.12  | 5.94 |
| Qwen2.5-7B-Instruct      | 7.62B | fp16 | Sampling | 4.06    | 3.45   | 3.86  | 3.20 |
| Qwen2.5-7B-Instruct      | 7.62B | bf16 | Sampling | 4.29    | 3.54   | 3.97  | 3.28 |
| Qwen3-4B                 | 4.02B | fp16 | Sampling | 6.22    | 3.92   | 5.55  | 2.61 |
| Qwen3-4B                 | 4.02B | bf16 | Sampling | 6.39    | 3.58   | 5.69  | 2.53 |
| Qwen3-0.6B               | 0.75B  | fp16 | Sampling | 21.35   | 10.38  | 18.10 | 6.10 |
| Qwen3-0.6B               | 0.75B  | bf16 | Sampling | 21.79   | 12.29  | 18.50 | 8.97 |
